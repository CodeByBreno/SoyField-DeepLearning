{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3896458-2b89-4668-bd9f-55d795194d46",
   "metadata": {},
   "source": [
    "# Projeto para reconhecimento do estágio de desenvolvimento de Culturas de Soja\n",
    "\n",
    "Esse projeto foi desenvolvido para disciplina de Deep Learning, e o objetivo é utilizar o TensorFlow/Keras para reconhecer o estágio de desenvolvimento de plantações de soja, tomando como base um conjunto de imagens ilustrativas fornecidas pela Bayer. A maior parte do código foi baseada no vídeo que se encontra no link: https://www.youtube.com/watch?v=jztwpsIzEGc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122dfad-8ce1-44fa-82bf-b8c0308f0f15",
   "metadata": {},
   "source": [
    "# 0. Criando a base de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe11496-c58b-4a17-8dfb-ab171dc30bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para as pastas de treino e teste\n",
    "import os\n",
    "\n",
    "train_dir = os.path.join('data', 'TRN')\n",
    "test_dir = os.path.join('data', 'TST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7ff7b9-0ff4-4534-be3a-c2fe0e7b07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = os.path.join('data', 'VAL')\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1,9):\n",
    "    os.makedirs(os.path.join(val_dir, str(i)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede673ce-85e6-4124-94a2-8d7697ca9a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train = os.listdir(os.path.join(train_dir, '1'));\n",
    "len(files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e66f770-6d62-4e92-abb1-bdd3384d6986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_test = os.listdir(os.path.join(test_dir, '1'));\n",
    "len(files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb33398b-7613-47c5-8654-19fc9ccd39b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_val = os.listdir(os.path.join(val_dir, '1'));\n",
    "len(files_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ab4b7a-fbc5-4eae-a7af-30d8278c9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_files_train = len(files_train)\n",
    "length_files_teste = len(files_test)\n",
    "length_files_val = len(files_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2966ac-b47b-42d8-92b4-584aeec686eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRN/1 : 1312\n",
      "TRN/2 : 1312\n",
      "TRN/3 : 1312\n",
      "TRN/4 : 1312\n",
      "TRN/5 : 1312\n",
      "TRN/6 : 1312\n",
      "TRN/7 : 1312\n",
      "TRN/8 : 1312\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    size = len(os.listdir(os.path.join(train_dir, str(i))))\n",
    "    print(f'TRN/{i} : {size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3988ab57-15e4-46d0-a787-55bd3b60e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TST/1 : 657\n",
      "TST/2 : 657\n",
      "TST/3 : 657\n",
      "TST/4 : 657\n",
      "TST/5 : 657\n",
      "TST/6 : 657\n",
      "TST/7 : 657\n",
      "TST/8 : 657\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    size = len(os.listdir(os.path.join(test_dir, str(i))))\n",
    "    print(f'TST/{i} : {size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c38c3a-1fd4-4364-98bf-b42bb9b4efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL/1 : 761\n",
      "VAL/2 : 761\n",
      "VAL/3 : 761\n",
      "VAL/4 : 761\n",
      "VAL/5 : 761\n",
      "VAL/6 : 761\n",
      "VAL/7 : 761\n",
      "VAL/8 : 761\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    size = len(os.listdir(os.path.join(val_dir, str(i))))\n",
    "    print(f'VAL/{i} : {size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9fc951-4766-494b-916f-9b132c0beefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport shutil\\nimport random\\n\\n# Para cada categoria, pegar um número específico de imagens para validação\\ncategories = os.listdir(train_dir)\\n\\nfor category in [\\'1\\', \\'2\\', \\'3\\', \\'4\\', \\'5\\', \\'6\\', \\'7\\', \\'8\\']:\\n    # Caminhos para as categorias de treino e teste\\n    train_category_dir = os.path.join(train_dir, category)\\n    test_category_dir = os.path.join(test_dir, category)\\n    \\n    # Listar as imagens de cada categoria\\n    train_images = os.listdir(train_category_dir)\\n    test_images = os.listdir(test_category_dir)\\n\\n    # Pegar as 50 primeiras imagens de treino e 100 imagens de teste\\n    val_train_images = random.sample(train_images, int(0.1*length_files_train))\\n    val_test_images = random.sample(test_images, int(0.1*length_files_teste))\\n\\n    # Embaralhar as imagens para garantir aleatoriedade\\n    val_images = val_train_images + val_test_images\\n    random.shuffle(val_images)\\n\\n    # Criar a pasta de validação da categoria, se não existir\\n    val_category_dir = os.path.join(val_dir, category)\\n    os.makedirs(val_category_dir, exist_ok=True)\\n\\n    # Mover as imagens de treino e teste para a pasta de validação\\n    for image in val_images:\\n        # Caminho completo da imagem\\n        if image in val_train_images:\\n            src = os.path.join(train_category_dir, image)\\n        else:\\n            src = os.path.join(test_category_dir, image)\\n        \\n        dst = os.path.join(val_category_dir, image)\\n        \\n        # Mover para a pasta de validação\\n        shutil.move(src, dst)\\n\\nprint(\"Conjunto de validação criado com sucesso!\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Para cada categoria, pegar um número específico de imagens para validação\n",
    "categories = os.listdir(train_dir)\n",
    "\n",
    "for category in ['1', '2', '3', '4', '5', '6', '7', '8']:\n",
    "    # Caminhos para as categorias de treino e teste\n",
    "    train_category_dir = os.path.join(train_dir, category)\n",
    "    test_category_dir = os.path.join(test_dir, category)\n",
    "    \n",
    "    # Listar as imagens de cada categoria\n",
    "    train_images = os.listdir(train_category_dir)\n",
    "    test_images = os.listdir(test_category_dir)\n",
    "\n",
    "    # Pegar as 50 primeiras imagens de treino e 100 imagens de teste\n",
    "    val_train_images = random.sample(train_images, int(0.1*length_files_train))\n",
    "    val_test_images = random.sample(test_images, int(0.1*length_files_teste))\n",
    "\n",
    "    # Embaralhar as imagens para garantir aleatoriedade\n",
    "    val_images = val_train_images + val_test_images\n",
    "    random.shuffle(val_images)\n",
    "\n",
    "    # Criar a pasta de validação da categoria, se não existir\n",
    "    val_category_dir = os.path.join(val_dir, category)\n",
    "    os.makedirs(val_category_dir, exist_ok=True)\n",
    "\n",
    "    # Mover as imagens de treino e teste para a pasta de validação\n",
    "    for image in val_images:\n",
    "        # Caminho completo da imagem\n",
    "        if image in val_train_images:\n",
    "            src = os.path.join(train_category_dir, image)\n",
    "        else:\n",
    "            src = os.path.join(test_category_dir, image)\n",
    "        \n",
    "        dst = os.path.join(val_category_dir, image)\n",
    "        \n",
    "        # Mover para a pasta de validação\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Conjunto de validação criado com sucesso!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e996d-2005-4efa-a141-b2e8922de87c",
   "metadata": {},
   "source": [
    "# 1. Configurações Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e04b06-557a-4f3b-86b0-776f64bdc72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\dev\\anaconda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: opencv-python in c:\\dev\\anaconda\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in c:\\dev\\anaconda\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\dev\\anaconda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\dev\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\dev\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\dev\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\dev\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\dev\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\dev\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\dev\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\dev\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\dev\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\dev\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\dev\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0267912-f0e7-49d5-9b21-d2516af0fe5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ------------------\n",
      "absl-py                           2.1.0\n",
      "aext-assistant                    4.0.15\n",
      "aext-assistant-server             4.0.15\n",
      "aext-core                         4.0.15\n",
      "aext-core-server                  4.0.15\n",
      "aext-panels                       4.0.15\n",
      "aext-panels-server                4.0.15\n",
      "aext-share-notebook               4.0.15\n",
      "aext-share-notebook-server        4.0.15\n",
      "aext-shared                       4.0.15\n",
      "aiobotocore                       2.12.3\n",
      "aiohappyeyeballs                  2.4.0\n",
      "aiohttp                           3.10.5\n",
      "aioitertools                      0.7.1\n",
      "aiosignal                         1.2.0\n",
      "alabaster                         0.7.16\n",
      "altair                            5.0.1\n",
      "anaconda-anon-usage               0.4.4\n",
      "anaconda-catalogs                 0.2.0\n",
      "anaconda-client                   1.12.3\n",
      "anaconda-cloud-auth               0.5.1\n",
      "anaconda-navigator                2.6.3\n",
      "anaconda-project                  0.11.1\n",
      "annotated-types                   0.6.0\n",
      "anyio                             4.2.0\n",
      "appdirs                           1.4.4\n",
      "archspec                          0.2.3\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.2.3\n",
      "astroid                           2.14.2\n",
      "astropy                           6.1.3\n",
      "astropy-iers-data                 0.2024.9.2.0.33.23\n",
      "asttokens                         2.0.5\n",
      "astunparse                        1.6.3\n",
      "async-lru                         2.0.4\n",
      "atomicwrites                      1.4.0\n",
      "attrs                             23.1.0\n",
      "Automat                           20.2.0\n",
      "autopep8                          2.0.4\n",
      "Babel                             2.11.0\n",
      "bcrypt                            3.2.0\n",
      "beautifulsoup4                    4.12.3\n",
      "binaryornot                       0.4.4\n",
      "black                             24.8.0\n",
      "bleach                            4.1.0\n",
      "blinker                           1.6.2\n",
      "bokeh                             3.6.0\n",
      "boltons                           23.0.0\n",
      "botocore                          1.34.69\n",
      "Bottleneck                        1.3.7\n",
      "Brotli                            1.0.9\n",
      "cachetools                        5.3.3\n",
      "certifi                           2024.8.30\n",
      "cffi                              1.17.1\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                3.3.2\n",
      "click                             8.1.7\n",
      "cloudpickle                       3.0.0\n",
      "colorama                          0.4.6\n",
      "colorcet                          3.1.0\n",
      "comm                              0.2.1\n",
      "conda                             24.11.0\n",
      "conda-build                       24.9.0\n",
      "conda-content-trust               0.2.0\n",
      "conda_index                       0.5.0\n",
      "conda-libmamba-solver             24.9.0\n",
      "conda-pack                        0.7.1\n",
      "conda-package-handling            2.3.0\n",
      "conda_package_streaming           0.10.0\n",
      "conda-repo-cli                    1.0.114\n",
      "conda-token                       0.5.0+1.g2209e04\n",
      "constantly                        23.10.4\n",
      "contourpy                         1.2.0\n",
      "cookiecutter                      2.6.0\n",
      "cryptography                      43.0.0\n",
      "cssselect                         1.2.0\n",
      "cycler                            0.11.0\n",
      "cytoolz                           0.12.2\n",
      "dask                              2024.8.2\n",
      "dask-expr                         1.1.13\n",
      "datashader                        0.16.3\n",
      "debugpy                           1.6.7\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "diff-match-patch                  20200713\n",
      "dill                              0.3.8\n",
      "distributed                       2024.8.2\n",
      "distro                            1.9.0\n",
      "docstring-to-markdown             0.11\n",
      "docutils                          0.18.1\n",
      "et-xmlfile                        1.1.0\n",
      "executing                         0.8.3\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.13.1\n",
      "flake8                            7.0.0\n",
      "Flask                             3.0.3\n",
      "flatbuffers                       24.3.25\n",
      "fonttools                         4.51.0\n",
      "fqdn                              1.5.1\n",
      "frozendict                        2.4.2\n",
      "frozenlist                        1.4.0\n",
      "fsspec                            2024.6.1\n",
      "gast                              0.6.0\n",
      "gensim                            4.3.3\n",
      "gitdb                             4.0.7\n",
      "GitPython                         3.1.43\n",
      "google-pasta                      0.2.0\n",
      "greenlet                          3.0.1\n",
      "grpcio                            1.68.0\n",
      "h11                               0.14.0\n",
      "h5py                              3.11.0\n",
      "HeapDict                          1.0.1\n",
      "holoviews                         1.19.1\n",
      "httpcore                          1.0.2\n",
      "httpx                             0.27.0\n",
      "hvplot                            0.11.0\n",
      "hyperlink                         21.0.0\n",
      "idna                              3.7\n",
      "imagecodecs                       2023.1.23\n",
      "imageio                           2.33.1\n",
      "imagesize                         1.4.1\n",
      "imbalanced-learn                  0.12.3\n",
      "importlib-metadata                7.0.1\n",
      "incremental                       22.10.0\n",
      "inflection                        0.5.1\n",
      "iniconfig                         1.1.1\n",
      "intake                            2.0.7\n",
      "intervaltree                      3.1.0\n",
      "ipykernel                         6.28.0\n",
      "ipython                           8.27.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.8.1\n",
      "isoduration                       20.11.0\n",
      "isort                             5.13.2\n",
      "itemadapter                       0.3.0\n",
      "itemloaders                       1.1.0\n",
      "itsdangerous                      2.2.0\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.19.1\n",
      "jellyfish                         1.0.1\n",
      "Jinja2                            3.1.4\n",
      "jmespath                          1.0.1\n",
      "joblib                            1.4.2\n",
      "json5                             0.9.6\n",
      "jsonpatch                         1.33\n",
      "jsonpointer                       2.1\n",
      "jsonschema                        4.23.0\n",
      "jsonschema-specifications         2023.7.1\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    8.6.0\n",
      "jupyter-console                   6.6.3\n",
      "jupyter_core                      5.7.2\n",
      "jupyter-events                    0.10.0\n",
      "jupyter-lsp                       2.2.0\n",
      "jupyter_server                    2.14.1\n",
      "jupyter_server_terminals          0.4.4\n",
      "jupyterlab                        4.2.5\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.27.3\n",
      "jupyterlab-widgets                1.0.0\n",
      "keras                             3.6.0\n",
      "keyring                           24.3.1\n",
      "kiwisolver                        1.4.4\n",
      "lazy_loader                       0.4\n",
      "lazy-object-proxy                 1.10.0\n",
      "lckr_jupyterlab_variableinspector 3.1.0\n",
      "libarchive-c                      5.1\n",
      "libclang                          18.1.1\n",
      "libmambapy                        1.5.8\n",
      "linkify-it-py                     2.0.0\n",
      "llvmlite                          0.43.0\n",
      "lmdb                              1.4.1\n",
      "locket                            1.0.0\n",
      "lxml                              5.2.1\n",
      "lz4                               4.3.2\n",
      "Markdown                          3.4.1\n",
      "markdown-it-py                    2.2.0\n",
      "MarkupSafe                        2.1.3\n",
      "matplotlib                        3.9.2\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.7.0\n",
      "mdit-py-plugins                   0.3.0\n",
      "mdurl                             0.1.0\n",
      "menuinst                          2.1.2\n",
      "mistune                           2.0.4\n",
      "mkl_fft                           1.3.10\n",
      "mkl_random                        1.2.7\n",
      "mkl-service                       2.4.0\n",
      "ml-dtypes                         0.4.1\n",
      "more-itertools                    10.3.0\n",
      "mpmath                            1.3.0\n",
      "msgpack                           1.0.3\n",
      "multidict                         6.0.4\n",
      "multipledispatch                  0.6.0\n",
      "mypy                              1.11.2\n",
      "mypy-extensions                   1.0.0\n",
      "namex                             0.0.8\n",
      "navigator-updater                 0.5.1\n",
      "nbclient                          0.8.0\n",
      "nbconvert                         7.16.4\n",
      "nbformat                          5.10.4\n",
      "nest-asyncio                      1.6.0\n",
      "networkx                          3.3\n",
      "nltk                              3.9.1\n",
      "notebook                          7.2.2\n",
      "notebook_shim                     0.2.3\n",
      "numba                             0.60.0\n",
      "numexpr                           2.8.7\n",
      "numpy                             1.26.4\n",
      "numpydoc                          1.7.0\n",
      "opencv-python                     4.10.0.84\n",
      "openpyxl                          3.1.5\n",
      "opt_einsum                        3.4.0\n",
      "optree                            0.13.1\n",
      "overrides                         7.4.0\n",
      "packaging                         24.1\n",
      "pandas                            2.2.2\n",
      "pandocfilters                     1.5.0\n",
      "panel                             1.5.2\n",
      "param                             2.1.1\n",
      "paramiko                          2.8.1\n",
      "parsel                            1.8.1\n",
      "parso                             0.8.3\n",
      "partd                             1.4.1\n",
      "pathspec                          0.10.3\n",
      "patsy                             0.5.6\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "pillow                            10.4.0\n",
      "pip                               24.2\n",
      "pkce                              1.0.3\n",
      "pkginfo                           1.10.0\n",
      "platformdirs                      3.10.0\n",
      "plotly                            5.24.1\n",
      "pluggy                            1.0.0\n",
      "ply                               3.11\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.43\n",
      "Protego                           0.1.16\n",
      "protobuf                          4.25.3\n",
      "psutil                            5.9.0\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py-cpuinfo                        9.0.0\n",
      "pyarrow                           16.1.0\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.11.1\n",
      "pycosat                           0.6.6\n",
      "pycparser                         2.21\n",
      "pyct                              0.5.0\n",
      "pycurl                            7.45.3\n",
      "pydantic                          2.8.2\n",
      "pydantic_core                     2.20.1\n",
      "pydeck                            0.8.0\n",
      "PyDispatcher                      2.0.5\n",
      "pydocstyle                        6.3.0\n",
      "pyerfa                            2.0.1.4\n",
      "pyflakes                          3.2.0\n",
      "Pygments                          2.15.1\n",
      "PyJWT                             2.8.0\n",
      "pylint                            2.16.2\n",
      "pylint-venv                       3.0.3\n",
      "pyls-spyder                       0.4.0\n",
      "PyNaCl                            1.5.0\n",
      "pyodbc                            5.1.0\n",
      "pyOpenSSL                         24.2.1\n",
      "pyparsing                         3.1.2\n",
      "PyQt5                             5.15.10\n",
      "PyQt5-sip                         12.13.0\n",
      "PyQtWebEngine                     5.15.6\n",
      "PySocks                           1.7.1\n",
      "pytest                            7.4.4\n",
      "python-dateutil                   2.9.0.post0\n",
      "python-dotenv                     0.21.0\n",
      "python-json-logger                2.0.7\n",
      "python-lsp-black                  2.0.0\n",
      "python-lsp-jsonrpc                1.1.2\n",
      "python-lsp-server                 1.10.0\n",
      "python-slugify                    5.0.2\n",
      "pytoolconfig                      1.2.6\n",
      "pytz                              2024.1\n",
      "pyviz_comms                       3.0.2\n",
      "PyWavelets                        1.7.0\n",
      "pywin32                           305.1\n",
      "pywin32-ctypes                    0.2.2\n",
      "pywinpty                          2.0.10\n",
      "PyYAML                            6.0.1\n",
      "pyzmq                             25.1.2\n",
      "QDarkStyle                        3.2.3\n",
      "qstylizer                         0.2.2\n",
      "QtAwesome                         1.3.1\n",
      "qtconsole                         5.5.1\n",
      "QtPy                              2.4.1\n",
      "queuelib                          1.6.2\n",
      "referencing                       0.30.2\n",
      "regex                             2024.9.11\n",
      "requests                          2.32.3\n",
      "requests-file                     1.5.1\n",
      "requests-toolbelt                 1.0.0\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rich                              13.7.1\n",
      "rope                              1.12.0\n",
      "rpds-py                           0.10.6\n",
      "Rtree                             1.0.1\n",
      "ruamel.yaml                       0.18.6\n",
      "ruamel.yaml.clib                  0.2.8\n",
      "ruamel-yaml-conda                 0.17.21\n",
      "s3fs                              2024.6.1\n",
      "scikit-image                      0.24.0\n",
      "scikit-learn                      1.5.1\n",
      "scipy                             1.13.1\n",
      "Scrapy                            2.11.1\n",
      "seaborn                           0.13.2\n",
      "semver                            3.0.2\n",
      "Send2Trash                        1.8.2\n",
      "service-identity                  18.1.0\n",
      "setuptools                        75.1.0\n",
      "sip                               6.7.12\n",
      "six                               1.16.0\n",
      "smart-open                        5.2.1\n",
      "smmap                             4.0.0\n",
      "sniffio                           1.3.0\n",
      "snowballstemmer                   2.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.5\n",
      "Sphinx                            7.3.7\n",
      "sphinxcontrib-applehelp           1.0.2\n",
      "sphinxcontrib-devhelp             1.0.2\n",
      "sphinxcontrib-htmlhelp            2.0.0\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              1.0.3\n",
      "sphinxcontrib-serializinghtml     1.1.10\n",
      "spyder                            5.5.1\n",
      "spyder-kernels                    2.5.0\n",
      "SQLAlchemy                        2.0.34\n",
      "stack-data                        0.2.0\n",
      "statsmodels                       0.14.2\n",
      "streamlit                         1.37.1\n",
      "sympy                             1.13.2\n",
      "tables                            3.10.1\n",
      "tabulate                          0.9.0\n",
      "tblib                             1.7.0\n",
      "tenacity                          8.2.3\n",
      "tensorboard                       2.18.0\n",
      "tensorboard-data-server           0.7.2\n",
      "tensorflow                        2.18.0\n",
      "tensorflow_intel                  2.18.0\n",
      "termcolor                         2.5.0\n",
      "terminado                         0.17.1\n",
      "text-unidecode                    1.3\n",
      "textdistance                      4.2.1\n",
      "threadpoolctl                     3.5.0\n",
      "three-merge                       0.1.1\n",
      "tifffile                          2023.4.12\n",
      "tinycss2                          1.2.1\n",
      "tldextract                        5.1.2\n",
      "toml                              0.10.2\n",
      "tomli                             2.0.1\n",
      "tomlkit                           0.11.1\n",
      "toolz                             0.12.0\n",
      "tornado                           6.4.1\n",
      "tqdm                              4.66.5\n",
      "traitlets                         5.14.3\n",
      "truststore                        0.8.0\n",
      "Twisted                           23.10.0\n",
      "twisted-iocpsupport               1.0.2\n",
      "typing_extensions                 4.11.0\n",
      "tzdata                            2023.3\n",
      "uc-micro-py                       1.0.1\n",
      "ujson                             5.10.0\n",
      "unicodedata2                      15.1.0\n",
      "Unidecode                         1.3.8\n",
      "uri-template                      1.3.0\n",
      "urllib3                           2.2.3\n",
      "w3lib                             2.1.2\n",
      "watchdog                          4.0.1\n",
      "wcwidth                           0.2.5\n",
      "webcolors                         24.11.1\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.8.0\n",
      "Werkzeug                          3.0.3\n",
      "whatthepatch                      1.0.2\n",
      "wheel                             0.44.0\n",
      "widgetsnbextension                3.6.6\n",
      "win-inet-pton                     1.1.0\n",
      "wrapt                             1.14.1\n",
      "xarray                            2023.6.0\n",
      "xlwings                           0.32.1\n",
      "xyzservices                       2022.9.0\n",
      "yapf                              0.40.2\n",
      "yarl                              1.11.0\n",
      "zict                              3.0.0\n",
      "zipp                              3.17.0\n",
      "zope.interface                    5.4.0\n",
      "zstandard                         0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7c28cf-d027-443a-9808-b37b514bdb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8688600b-8824-4e3a-a869-8ab708b408c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86ebd751-c44a-431b-9551-d26a8da240b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') # Por enquanto, minha GPU não está sendo detectada. Vou tentar fazer sem mesmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac0efa-21ea-41f7-9883-fab441f34921",
   "metadata": {},
   "source": [
    "# 2. Importando e tratando as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fa83f-bc5d-401d-a0cd-815fe4f4ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, Rescaling, RandomHeight, RandomWidth, RandomContrast\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "data_dir = 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e3b59-4491-4996-8b05-a41ac2e18ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função personalizada para converter RGB para HSV e ajustar o contraste\n",
    "def rgb_to_hsv(image, label):\n",
    "    # Converter RGB para HSV\n",
    "    hsv_image = tf.image.rgb_to_hsv(image)\n",
    "    \n",
    "    return hsv_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd5473-324f-4b40-a99e-09e7334da0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def enhance(image, label, green_factor=2):\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3a4b1-1f93-4458-91d2-7815a34c909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(image, label):\n",
    "    label_one_hot = to_categorical(label, num_classes=8)\n",
    "    return image, label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe95ed3-bf89-4d86-b9be-0b8f58f3acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar a imagem (para a faixa [0, 1])\n",
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalizar após ajuste de contraste\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c63a4-f390-465c-a0c0-87f0de42d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de treino\n",
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/TRN',\n",
    "    image_size=(256, 256),  # Garante que as imagens sejam redimensionadas para 256x256\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# Copiar o dataset original sem augmentação (se precisar para fins de comparação)\n",
    "data_train_without_augmentation = data_train\n",
    "\n",
    "# Definindo as camadas de Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),            # Flip horizontal aleatório\n",
    "    RandomRotation(0.4),                 # Rotação aleatória até 40% (0.4)\n",
    "    RandomZoom(0.2),                     # Zoom aleatório de até 20%\n",
    "    RandomWidth(0.2),                    # Variação aleatória na largura até 20%\n",
    "    RandomHeight(0.2),                   # Variação aleatória na altura até 20%\n",
    "    RandomContrast(0.2),                 # Variação no contraste até 20%\n",
    "    tf.keras.layers.Resizing(256, 256),  # Garante que o tamanho seja restaurado para 256x256\n",
    "])\n",
    "\n",
    "# data_train = data_train.map(enhance)                                                                # Ajustar o contraste\n",
    "data_train = data_train.map(normalize)                                                              # Normalizar depois do ajuste\n",
    "data_train = data_train.map(lambda x, y: (data_augmentation(x, training=True), y))                  # Data augmentation\n",
    "#data_train = data_train.shuffle(buffer_size=100, reshuffle_each_iteration=True)                     # Embaralhar os dados\n",
    "data_train = data_train.cache()                                                                     # Cache de dados\n",
    "data_train = data_train.map(preprocess_labels).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # OneHotEncoding e prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76062785-b30d-45e6-b341-d5ff56f05537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma pipeline para importar as imagens (assim não precisam ser todas salvas em memória de uma vez)\n",
    "\n",
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/TST',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# Aplicando o pipeline no dataset de teste\n",
    "#data_test = data_test.map(adjust_contrast)                                                       # Ajustando o contraste\n",
    "data_test = data_test.map(normalize)                                                             # Normalizando a escala RGB após ajuste de contraste\n",
    "# data_test = data_test.map(rgb_to_hsv)                                                          # Usando HSV ao invés de RGB (opcional)\n",
    "data_test = data_test.cache()                                                                    # Cache de dados para otimização\n",
    "data_test = data_test.map(preprocess_labels).prefetch(buffer_size=tf.data.experimental.AUTOTUNE) # OneHotEnconding e prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8f6bd-e9e0-4866-be4d-c977ccc3e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/VAL',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# Aplicando o pipeline no dataset de validação\n",
    "#data_val = data_val.map(adjust_contrast)                                                         # Ajustando o contraste\n",
    "data_val = data_val.map(normalize)                                                               # Normalizando a escala RGB após ajuste de contraste\n",
    "# data_val = data_val.map(rgb_to_hsv)                                                            # Usando HSV ao invés de RGB (opcional)\n",
    "data_val = data_val.cache()                                                                      # Cache de dados\n",
    "data_val = data_val.map(preprocess_labels).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)   # OneHotEncondig e prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64f6fd-ce20-4037-9a4c-0095326b5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um iterator para cada pipeline. \n",
    "# Esses objetos serão usados para \"puxar\" um batch novo de imagens para memória sempre que necessário\n",
    "\n",
    "data_train_iterator = data_train.as_numpy_iterator()\n",
    "data_test_iterator = data_test.as_numpy_iterator()\n",
    "data_val_iterator = data_val.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe0172-76cf-40ca-9017-ac3f1d0cae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = data_train_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d79e20-8add-4c17-986a-4c98538ace59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Os valores estão entre {batch_train[0].min()} e {batch_train[0].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f332d4a-ba6d-467e-96d4-7f22d06a53b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# O batch é um tupla formada por uma lista de valores \n",
    "# (que são as imagens importadas em memória no formato de uma lista de listas com três elementos - cores BGR - do NumPy) \n",
    "# E uma lista de rótulos, que se referem a pasta (e futuramente, classificação) da imagem\n",
    "\n",
    "# As cores estão no formato BGR porque esse é o padrão do NumPy, o que exige uma conversão posterior (geralmente)\n",
    "\n",
    "print(batch_train[0]) # matrizes NumPy que representam as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf0abf-5089-47e4-bf83-f0790447e720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rótulos que representam as categorias em OneHotEncoding \n",
    "# (ou seja, cada uma é uma lista com zeros e ums, que representa o número referente à categoria - de 0 7 - )\n",
    "\n",
    "print(batch_train[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd6388-b19b-4732-b471-b1de0a2bcadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos converter os labels de OntHotEncondig para números normais, e ver as categorias de cada imagem do batch normalmente\n",
    "# (lembrando que o batch tem 32 imagens, por isso 32 valores na lista)\n",
    "\n",
    "one_hot_labels = batch_train[1]\n",
    "class_labels = np.argmax(one_hot_labels, axis=1)\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d120bc5-285f-4e00-a54c-c5e3c0d80067",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_train[0]) # cada batch importa 32 imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bac7e-3c91-4452-b507-c719851251a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_train[0][0][0][0]) # um pixel (com as regularização, seus valores estarão entre 0 e 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633ae1e-3dbd-4664-ab4b-56f5fa68e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(255*batch_train[0][0][0][0]) # um pixel com os valores entre 0 e 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd22471-f3f6-4f21-b68b-c5493506048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_train[0][0][0]) # uma linha de pixels da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24140e-08c2-427f-9500-2ba7df7ab4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_train[0][0]) # uma lista de linhas - ou seja, a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8db0a1-2a7f-4b86-89e8-e6c8b16e6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = data_train_iterator.next()\n",
    "\n",
    "ig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch_train[0][:4]):\n",
    "    # Exibindo a imagem\n",
    "    ax[idx].imshow((255*img).astype(int))\n",
    "    \n",
    "    # Convertendo One-Hot para número\n",
    "    label_number = tf.argmax(batch_train[1][idx]).numpy()  # Converte a posição da classe para um número\n",
    "    \n",
    "    # Definindo o título com o número da classe\n",
    "    ax[idx].title.set_text(f\"Classe: {label_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f443b3-16e6-4df2-ba28-189e6bb64203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comparação, vamos ver as imagens plotadas sem data augmentation\n",
    "\n",
    "batch_without_augmentation = data_train_without_augmentation.map(lambda x,y: (x/255, y)).as_numpy_iterator().next()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch_without_augmentation[0][:4]):\n",
    "    ax[idx].imshow((255*img).astype(int))\n",
    "    ax[idx].title.set_text(f\"Classe: {batch_without_augmentation[1][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d01ae9-6849-4a3b-9d51-6172accaadb0",
   "metadata": {},
   "source": [
    "# 3. Construindo o Modelo de Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe46347-1ee6-468c-bf18-7febd2d564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c47ba3-2951-40cf-87e7-c07018e228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 2\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2df8d-6a9a-40fb-b26e-2ac9cae3cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 3\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(576, activation='relu'))\n",
    "\n",
    "model.add(Dense(35, activation='relu')) \n",
    "\n",
    "model.add(Dense(70, activation='relu')) \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8e7ec-99a1-415c-914b-2e793b08890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 4\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))  \n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40798157-469f-425a-9025-f784ab8fb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 5\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), strides = (2,2), padding='same', input_shape=(256,256,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d972bfe-e3be-4689-97db-d9b1bee4b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 2 sendo reeutilizada com o conjunto de validação modificado\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87414a18-4551-4587-82b0-bb83f746500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 8\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))  \n",
    "\n",
    "model.add(Conv2D(62, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1de474-688f-4eb1-aadf-fc7c2e351a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 9\n",
    "\n",
    "'''\n",
    "# Definir a arquitetura da CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))  # Tamanho da imagem 256x256 com 3 canais (RGB)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Terceira camada convolucional\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Quarta camada convolucional\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Achatar para conectar a camada densa\n",
    "model.add(Flatten())\n",
    "\n",
    "# Camada totalmente conectada\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Camada de saída para 8 classes (softmax para classificação)\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Exibir o resumo da arquitetura\n",
    "model.summary()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375a721-7bdb-47db-b9e1-f1a75d9409f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 10\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))  \n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fe44d-a4e0-4988-acf5-7c50f42466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura 11\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(576, activation='relu'))\n",
    "\n",
    "model.add(Dense(35, activation='relu')) \n",
    "\n",
    "model.add(Dense(70, activation='relu')) \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826db07-4f55-40e3-beb3-3a36ce5ab800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e84a11-894f-4bd4-9a46-39e0a7cb5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# optimizer = Adam(learning_rate=0.0001) \n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "# optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0001, weight_decay=1e-5)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "                loss=tf.losses.CategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e50841-54f3-42aa-8ed8-65c372650931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f19092-0ec4-4504-8f42-6b6bfdc02457",
   "metadata": {},
   "source": [
    "# 4. Treinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b384e6-af02-490b-b33b-4094f97c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "hist = model.fit(\n",
    "    data_train,\n",
    "    epochs=5,\n",
    "    validation_data=data_val,\n",
    "    callbacks=[tensorboard_callback, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77390507-e7af-4a56-b09a-e946620c9c18",
   "metadata": {},
   "source": [
    "# 5. Estatísticas do Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54781e77-8f31-4dbd-bbcd-2ebd0e8cbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb0a8d-c10c-4975-ab2d-1f3b4b422105",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5c06f-3d73-475d-a693-89bfef8754d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45136c15-7975-49fb-a68a-b593f6ea72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc3ac6-61bc-4f6e-9d92-6f27045e444e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in data_test.as_numpy_iterator():\n",
    "    X, y = batch  # y é o vetor de rótulos com 32 categorias\n",
    "    yhat = model.predict(X)  # yhat é um array de forma (32, 8), com as previsões de probabilidade\n",
    "    \n",
    "    # Converte as probabilidades para rótulos pegando o índice da maior probabilidade\n",
    "    yhat_labels = tf.argmax(yhat, axis=1)  # yhat_labels será um vetor de rótulos, assim como y\n",
    "    \n",
    "    # Agora, atualize as métricas usando y e yhat_labels, que possuem a mesma forma\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01f4e8-a33b-4272-9831-ca49cb0d78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a43e2-a724-49c8-861c-775c2efb7537",
   "metadata": {},
   "source": [
    "# 6. Testando o Modelo diretamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7488a-0d66-4060-bd7f-77256eb4f55b",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffeef8-770f-433b-872b-cd860d63a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def showImage(path, category, model):\n",
    "    img = cv2.imread(path)\n",
    "    image = tf.image.resize(img, (256,256))\n",
    "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    # Prever a classe da imagem\n",
    "    yhat = model.predict(np.expand_dims(image / 255, 0))  \n",
    "    predicted_class = np.argmax(yhat)  # A classe predita\n",
    "    details = \"\"\n",
    "    \n",
    "    # Gerar as probabilidades para todas as classes\n",
    "    for i, prediction in enumerate(yhat[0]):  \n",
    "        details += f'Probability of Class {i + 1}: {prediction * 100:.2f}%\\n'\n",
    "    \n",
    "    # Converter a imagem de BGR para RGB\n",
    "    rgb_img = cv2.cvtColor(image.numpy(), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Criar a figura e os eixos\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))  # Ajuste o tamanho da figura (largura x altura)\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    ax.imshow(rgb_img)\n",
    "    \n",
    "    # Título com a categoria\n",
    "    ax.set_title(f\"Classe: {category}\\nPrevisão: {predicted_class + 1}\", fontsize=14)\n",
    "    \n",
    "    # Adicionar as probabilidades das classes como rodapé\n",
    "    fig.text(0.5, -0.05, details, ha='center', fontsize=10, color='gray', va='bottom')\n",
    "    \n",
    "    # Ajustar o layout para evitar sobreposição\n",
    "    plt.tight_layout(pad=8.0)  # Aumente o valor de 'pad' para mais espaçamento\n",
    "    \n",
    "    # Exibir a imagem\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75cb4c-da25-431a-afa5-59b9a6fedf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category1.png', '1', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41453ee-2b79-4128-b087-3107ca527a28",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ce71a-77ab-4202-a9b6-66489639002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category2.png', '2', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96494a7e-067f-4ed7-9a8f-07c096373597",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9e10d-6d7d-4f81-975e-abea5d800dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category3.png', '3', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1687a-5fe7-4b20-9b63-3b97cedf9437",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557690b-91ea-4a6a-ac6e-635408193de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category4.png', '4', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e758a-a829-4054-87b7-44e8f5591df0",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768dd70-3ed5-4d3f-b7b4-d863bb08bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category5.png', '5', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f874df-f407-4c60-a692-f00b4879552c",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf34cf1-ee51-4549-8b2b-5b608f6ec61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category6.png', '6', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b3fce-d6a2-43c0-b77c-65113e11f440",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be89e9-8b14-4d18-8d27-97f1b22edf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category7.png', '7', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c54f7-d8c3-468a-9bc1-c3101c87bf42",
   "metadata": {},
   "source": [
    "## Reconhecendo uma imagem de categoria 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1cd71-3a53-497f-b0b8-11b9a3a6128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage('test/test_category8.png', '8', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8df7e1-e4f8-4d1b-bad0-9614498eeea8",
   "metadata": {},
   "source": [
    "# 7. Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78d146-606a-4542-9337-ce497fcf684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_modeasdascasasas\n",
    "#from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bc8a0-ef15-4bbf-8f4b-d15fa9ad32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','SoyField11.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992b070-a8bd-4dbb-9398-68c4b9cdddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/SoyField11.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cea88a-3131-4c1c-ad22-fb0d2d92953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('models', 'SoyField7.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4e674-0092-45f5-83d6-7b251b82e531",
   "metadata": {},
   "source": [
    "# 8. Classificando uma imagem grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc4965-96e6-483f-985c-f489261bc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def getPrediction(path):\n",
    "    img = cv2.imread(path)\n",
    "    image = tf.image.resize(img, (256,256))\n",
    "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    # Prever a classe da imagem\n",
    "    yhat = model.predict(np.expand_dims(image / 255, 0))  \n",
    "    predicted_class = np.argmax(yhat)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffe261-3390-45b1-b2d7-31b16520ad34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir = os.path.join('complete', 'image8');\n",
    "\n",
    "list_pred = {}\n",
    "total = len(os.listdir(image_dir))\n",
    "\n",
    "for i in range(1,9):\n",
    "    list_pred[i] = 0\n",
    "\n",
    "for imagePath in os.listdir(image_dir):\n",
    "    pred = getPrediction(os.path.join(image_dir, imagePath))\n",
    "    list_pred[pred+1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a33f68-9b2d-4d4d-a8b2-7ace9226ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d4f4d-28a6-433f-b98c-5ab93bd0ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (list_pred[6] + list_pred[7] > total*0.7) & (list_pred[6] < total*0.6):\n",
    "    print(\"A plantação está no ponto adequado para desseca\")\n",
    "else:\n",
    "    print(\"Ainda não é hora da desseca\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
